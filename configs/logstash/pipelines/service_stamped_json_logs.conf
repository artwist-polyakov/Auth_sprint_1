# Этот блок определяет источник данных, в данном случае логи от Beats, который прослушивает порт 5044
input {
  beats {
    port => '${LOGSTASH_PORT}'
  }
}

# Здесь определены операции фильтрации и обработки логов.
# В этом блоке выполняется проверка на принадлежность лога к известному сервису (по значению поля fields.service).
# Если сервис неизвестен, лог отбрасывается (drop {}).
# Затем, используется плагин json для разбора JSON-логов, которые были отправлены Filebeat.
# Далее, плагин date используется для определения временной метки логов на основе поля asctime.

filter {
  # Дропаем лог, если он пришел от неизвестного нам сервиса (по желанию)
  # Ниже я два раза указал host_metrics_app в списке - это не опечатка.
  # Какого-то лешего в условии, в массиве должно быть минимум 2 элемента.
  # Так как приложение у нас одно - просто дублируем
  # Поле service у нас появится благодаря конфигурированию Filebeat
  if [fields][service] not in ["logs", "logs"] {
    drop {}
  }
  # Оригинальный json-лог, который был сгенерирован вашим приложением, будет лежать по ключу message
  # (из filebeat'а логи прилетают не в чистом виде)
  json {
    source => "message"
  }
  # Говорим logstash'у, чтобы в качестве timestamp'а лога он брал именно наш timestamp
  # (в моем случае поле asctime в теле сообщения в формате "yyyy-MM-dd HH:mm:ss.SSS" и часовом поясе UTC)
  # и затем подтирал поле asctime.
  date {
    match => ["asctime", "yyyy-MM-dd HH:mm:ss.SSS"]
    timezone => "UTC"
    target => "@timestamp"
    remove_field => ["asctime"]
  }
}

# В этом блоке определяется, куда отправлять обработанные логи.
# В данном случае, логи выводятся в stdout для отладки (stdout {}),
# а также отправляются в Elasticsearch с указанием хоста, индекса и учетных данных аутентификации.
output {
  # Данная строка предназначена для отображения логов в стандартный вывод (stdout)
#   stdout {}
  # Пушим лог в elasticsearch, индекс будет создан автоматически по названию сервиса и текущей дате
  elasticsearch {
    hosts => '${ELASTICSEARCH_HOST}'
    index => "logs_%{[fields][service]}-%{+YYYY.MM.dd}"
  }
}