version: '3'

services:
  nginx:
    container_name: nginx
    build: ./nginx
    volumes:
      - static_volume:/var/www/static
      - media_volume:/var/www/media
      - admin_volume:/var/www/static/admin
    depends_on:
      - movies
      - auth
      - admin
    ports:
      - "8000:80"
      - "443:443"
    restart: on-failure

  admin:
    container_name: admin
    build: ./admin
    volumes:
      - admin_static:/var/www/static/admin
    expose:
      - "8000"
    env_file:
      - .env
    depends_on:
      - postgres
    restart: on-failure

  movies:
    container_name: movies
    build: ./movies
    expose:
      - "8000"
    env_file:
      - .env
    depends_on:
      - postgres
      - elasticsearch-node1
      - elasticsearch-node2
      - redis
      - jaeger
    restart: on-failure

  auth:
    container_name: auth
    build: ./auth
    expose:
      - "8000"
    env_file:
      - .env
    depends_on:
      - postgres
      - redis
      - jaeger
    restart: on-failure

  etl-elasticsearch:
    container_name: etl-elasticsearch
    build: ./etl_elasticsearch
    env_file:
      - .env
    depends_on:
      - postgres
      - elasticsearch-node1
      - elasticsearch-node2
      - redis
    restart: on-failure

  postgres:
    container_name: postgres
    image: postgres:${POSTGRES_VERSION}
    env_file:
      - .env
    volumes:
      - ./postgres/:/docker-entrypoint-initdb.d/
    ports:
      - "5432:5432"
    restart: on-failure

  elasticsearch-node1:
    image: elasticsearch:${STACK_VERSION}
    container_name: elasticsearch-node1
    env_file:
      - .env
    environment:
      - node.name=elasticsearch-node1
      - discovery.seed_hosts=elasticsearch-node1,elasticsearch-node2
      - cluster.initial_master_nodes=elasticsearch-node1
      - cluster.name=${ELASTIC_CLUSTER_NAME}
      - bootstrap.memory_lock=${MEMORY_LOCK}
      - "ES_JAVA_OPTS=-Xms256m -Xmx256m"
      - xpack.security.enabled=false
      - xpack.monitoring.collection.enabled=false
#      - xpack.license.self_generated.type=basic
    ulimits:
      memlock:
        soft: -1
        hard: -1
    restart: on-failure

  elasticsearch-node2:
    image: elasticsearch:${STACK_VERSION}
    container_name: elasticsearch-node2
    env_file:
      - .env
    environment:
      - node.name=elasticsearch-node2
      - discovery.seed_hosts=elasticsearch-node1,elasticsearch-node2
      - cluster.initial_master_nodes=elasticsearch-node1
      - cluster.name=${ELASTIC_CLUSTER_NAME}
      - bootstrap.memory_lock=${MEMORY_LOCK}
      - "ES_JAVA_OPTS=-Xms256m -Xmx256m"
      - xpack.security.enabled=false
      - xpack.monitoring.collection.enabled=false
#      - xpack.license.self_generated.type=basic
    depends_on:
      - elasticsearch-node1
    ulimits:
      memlock:
        soft: -1
        hard: -1
    restart: on-failure

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:v0.7.0
    ports:
      - ${KAFKA_PORT_UI}:${KAFKA_PORT_UI}
    environment:
      - KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_NAME=kraft
    restart: on-failure

  kafka:
    container_name: kafka
    image: bitnami/kafka:${KAFKA_VERSION}
    ports:
      - ${KAFKA_PORT}:${KAFKA_PORT}
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:${KAFKA_PORT_CONTROLLER}
      - KAFKA_KRAFT_CLUSTER_ID=${KAFKA_KRAFT_CLUSTER_ID}
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:${KAFKA_PORT_PLAINTEXT},CONTROLLER://:${KAFKA_PORT_CONTROLLER},EXTERNAL://:${KAFKA_PORT}
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:${KAFKA_PORT_PLAINTEXT},EXTERNAL://kafka:${KAFKA_PORT}
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
    volumes:
      - kafka_data:/bitnami/kafka
    restart: on-failure

  zookeeper:
    image: zookeeper:${ZOOKEEPER_VERSION}
    container_name: zookeeper
    hostname: zookeeper
    restart: on-failure

  clickhouse-node:
    image: clickhouse/clickhouse-server:${CLICKHOUSE_VERSION}
    container_name: clickhouse-node
    hostname: clickhouse-node
    ports:
      - ${CLICKHOUSE_PORT}:${CLICKHOUSE_PORT}
      - ${CLICKHOUSE_CLIENT_PORT}:${CLICKHOUSE_CLIENT_PORT}
    volumes:
      - ./ugc/data/node1:/etc/clickhouse-server
    env_file:
      - .env
    depends_on:
      - zookeeper
    restart: on-failure

  etl-clickhouse:
    build: ./etl_clickhouse
    container_name: etl-clickhouse
    command: bash -c "python main.py"
    env_file:
      - ./.env
    depends_on:
      - clickhouse-node
      - postgres
    restart: on-failure

  redis:
    container_name: redis
    image: redis:latest
    volumes:
      - ./core/redis.conf:/redis.conf
    command: [ "redis-server", "/redis.conf" ]
    restart: on-failure

  jaeger:
    container_name: jaeger
    image: jaegertracing/all-in-one:${JAEGER_VERSION}
    ports:
      - ${JAEGER_PORTS_1}
      - ${JAEGER_PORTS_2}
    environment:
      - LOG_LEVEL=debug
    env_file:
      - .env
    restart: on-failure

  ugc:
    container_name: ugc
    build: ./ugc
    ports:
      - ${FLASK_PORTS}
    env_file:
      - .env
    depends_on:
      - clickhouse-node
      - kafka
    restart: on-failure
    volumes:
      - ./logs/logs.log:/logs/logs.log:rw
    logging:
      driver: "json-file"
      options:
        max-file: "10"
        max-size: "10m"

  event-generator:
    container_name: event-generator
    build: ./event_generator
    ports:
      - ${GENERATOR_PORTS}
    env_file:
      - .env
    depends_on:
      - postgres
      - kafka

  etl-kafka:
    container_name: etl-kafka
    build: ./etl_kafka
    ports:
      - ${ETL_KAFKA_PORTS}
    env_file:
      - .env
    depends_on:
      - clickhouse-node
      - kafka

  locust:
    container_name: locust
    image: locustio/locust:master
    volumes:
      - ./locust:/locust
    env_file:
      - .env
    ports:
      - ${LOCUST_PORT}:${LOCUST_PORT}
    command: -f /locust/locustfile.py --master -H http://${FLASK_HOST}:${FLASK_PORT}

  locust-worker:
    container_name: locust-worker
    image: locustio/locust:master
    volumes:
      - ./locust:/locust
    env_file:
      - .env
    command: -f /locust/locustfile.py --worker --master-host ${LOCUST_HOST}

  logstash:
      container_name: logstash
      image: logstash:${STACK_VERSION}
      volumes:
        - ./configs/logstash/config.yml:/usr/share/logstash/config/logstash.yml:ro
        - ./configs/logstash/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro
        - ./configs/logstash/pipelines:/usr/share/logstash/config/pipelines:ro
      env_file:
        - .env
      environment:
        LS_JAVA_OPTS: "-Xmx512m -Xms512m"
      ports:
        - ${LOGSTASH_PORTS1}
        - ${LOGSTASH_PORTS2}
        - ${LOGSTASH_PORTS3}
      depends_on:
        - elasticsearch-node1

  kibana:
    container_name: kibana
    image: kibana:${STACK_VERSION}
    depends_on:
      - elasticsearch-node1
    volumes:
      - ./configs/kibana/config.yml:/usr/share/kibana/config/kibana.yml:ro
    env_file:
      - .env
    ports:
      - ${KIBANA_PORTS}

  filebeat:
    container_name: filebeat
    image: elastic/filebeat:${STACK_VERSION}
    command: filebeat -e -strict.perms=false
    volumes:
      - ./configs/filebeat/config.yml:/usr/share/filebeat/filebeat.yml:ro
      - ./logs/logs.log:/logs/logs.log:ro
    env_file:
      - .env
    depends_on:
      - elasticsearch-node1

volumes:
    static_volume:
    media_volume:
    admin_volume:
    admin_static:
    elasticsearch_data:
    redis_data:
    postgres_data:
    kafka_data:
    logs:
